<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  
  <title>[Day 8] Google Video Intelligence AI - 3 | Joseph &amp; Sandy</title>

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />

  <meta name="description" content="Google Video Intelligence AI API還有眾多的範例可以學習，今天再講兩個就結束這回合：Detecting shot changes、Recognizing text。  前情提要我先從python code example找到一些範例的影片  chicago.mp4: gs:&#x2F;&#x2F;cloud-ml-sandbox&#x2F;video&#x2F;chi">
<meta property="og:type" content="article">
<meta property="og:title" content="[Day 8] Google Video Intelligence AI - 3">
<meta property="og:url" content="https://josephmg.github.io/blog/2019/09/16/ithelp-2019-day8/index.html">
<meta property="og:site_name" content="Joseph &amp; Sandy">
<meta property="og:description" content="Google Video Intelligence AI API還有眾多的範例可以學習，今天再講兩個就結束這回合：Detecting shot changes、Recognizing text。  前情提要我先從python code example找到一些範例的影片  chicago.mp4: gs:&#x2F;&#x2F;cloud-ml-sandbox&#x2F;video&#x2F;chi">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://josephmg.github.io/blog/2019/09/16/ithelp-2019-day8/shot-text.jpg">
<meta property="article:published_time" content="2019-09-16T07:29:32.000Z">
<meta property="article:modified_time" content="2024-01-11T02:39:46.799Z">
<meta property="article:author" content="Joseph Chou">
<meta property="article:tag" content="Google AI">
<meta property="article:tag" content="鐵人賽">
<meta property="article:tag" content="Video Intelligence AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://josephmg.github.io/blog/2019/09/16/ithelp-2019-day8/shot-text.jpg">

  
    <link rel="alternate" href="/atom.xml" title="Joseph &amp; Sandy" type="application/atom+xml" />
  

  
  <!--[if lte IE 10 ]><link rel="shortcut icon" href="/images/favicon.ico"><![endif]-->
  <!--[if !IE]><!-->
  <link rel="shortcut icon" href="/images/favicon.png">

  <meta name="msapplication-TileImage" content="/images/favicon.png"/>
  <meta name="msapplication-TileColor" content="#000000"/>

  <link rel="apple-touch-icon" href="/images/apple-touch-icon-57x57.png" />
  <link rel="apple-touch-icon" sizes="72x72" href="/images/apple-touch-icon-72x72.png" />
  <link rel="apple-touch-icon" sizes="114x114" href="/images/apple-touch-icon-114x114.png" />
  <link rel="apple-touch-icon" sizes="144x144" href="/images/apple-touch-icon-144x144.png" />

  <link rel="icon" sizes="256x256" href="/images/favicon.png" />
  <!--<![endif]-->
  

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Raleway:wght@100;300;400;700&family=Source+Code+Pro:ital,wght@0,400;0,700;1,400&display=swap" rel="stylesheet">
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro|Material+Icons|Raleway:400,300,700" rel="stylesheet" type="text/css" />

  
<link rel="stylesheet" href="/generated/668-00d7cf7067e0204d9a1a.css">

<link rel="stylesheet" href="/generated/app-6513a95fd0931156078f.css">

<link rel="stylesheet" href="/generated/blog-0e6ef510d0b1ed0762da.css">


  
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-SC1JF1MZDV"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-SC1JF1MZDV');
  </script>
  <!-- End Google Analytics -->



  <script src="https://polyfill.io/v3/polyfill.min.js?features=es5,es6,es7,fetch,Object.entries,Object.values&flags=gated"></script>

<meta name="generator" content="Hexo 7.0.0"></head>
<body>

  
<div class="navbar-fixed">
  <nav id="main-navbar" class="grey lighten-5 z-depth-0" role="navigation">
    <div class="nav-wrapper container">

      <a id="logo-container" href="/" class="brand-logo center-align">
        <span>Joseph &amp; Sandy</span>
        <sub>Fullstack Engineer / Digital Marketing</sub>
      </a>

      <ul class="right hide-on-med-and-down">
        
          <li>
            <a class="main-nav-link" href="/">Home</a>
          </li>
        
          <li>
            <a class="main-nav-link" href="/blog">Blog</a>
          </li>
        
          <li>
            <a class="main-nav-link" href="/categories">Category</a>
          </li>
        
      </ul>

      <a href="#" data-target="nav-mobile" class="button-collapse sidenav-trigger">
        <i class="material-icons">menu</i>
      </a>
    </div>
  </nav>
</div>

<ul id="nav-mobile" class="sidenav">
  
  <li>
    <a class="main-nav-link" href="/">Home</a>
  </li>
  
  <li>
    <a class="main-nav-link" href="/blog">Blog</a>
  </li>
  
  <li>
    <a class="main-nav-link" href="/categories">Category</a>
  </li>
  
</ul>


  <div id="main-container">
    
<div class="container">
  <div class="row">
    <div class="col s12">


      <article id="blog-ithelp-2019-day8" class="article article-type-blog" itemscope itemprop="blogPost">

        <div class="article-inner">
          


          <header class="article-header">
          
              
  
    <h1 class="article-title header" itemprop="name">
      [Day 8] Google Video Intelligence AI - 3
    </h1>
  


          

            
              <div class="article-meta">
                <span class="">
                  <i class="fa fa-calendar"></i>
                  Published:
                  <time
                    datetime="2019-09-16T07:29:32.000Z"
                    itemprop="datePublished"
                    title="Date published"
                  >Sep 16, 2019</time>
                </span>
                <span class="article-author">
                  <i class="fa fa-user"></i>
                  <span itemprop="author"> Joseph </span>
                </span>
              </div>
            
          </header>


          <div class="article-entry " itemprop="articleBody">
            
              <p>Google Video Intelligence AI API還有眾多的範例可以學習，今天再講兩個就結束這回合：<a target="_blank" rel="noopener" href="https://cloud.google.com/video-intelligence/docs/analyze-shots?authuser=1">Detecting shot changes</a>、<a target="_blank" rel="noopener" href="https://cloud.google.com/video-intelligence/docs/text-detection?authuser=1">Recognizing text</a>。</p>
<blockquote>
<p>前情提要<br>我先從<a target="_blank" rel="noopener" href="https://github.com/GoogleCloudPlatform/python-docs-samples/tree/master/video/cloud-client/analyze">python code example</a>找到一些範例的影片</p>
<ul>
<li>chicago.mp4: gs:&#x2F;&#x2F;cloud-ml-sandbox&#x2F;video&#x2F;chicago.mp4</li>
<li>gbikes_dinosaur.mp4: gs:&#x2F;&#x2F;cloud-samples-data&#x2F;video&#x2F;gbikes_dinosaur.mp4</li>
<li>googlework_short.mp4: gs:&#x2F;&#x2F;python-docs-samples-tests&#x2F;video&#x2F;googlework_short.mp4</li>
</ul>
</blockquote>
<span id="more"></span>

<h3><span id="detecting-shot-changes"></span><a href="#detecting-shot-changes" class="header-anchor">#</a></h3><p>在範例裡我使用<code>gbikes_dinosaur.mp4</code>這個檔案，這是一部在Google園區拍gbike + 恐龍的影片。讓我直接把code貼上來，並改成大寫開頭讓外部呼叫。</p>
<figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">ShotChangeURI</span><span class="params">(w io.Writer, file <span class="type">string</span>)</span></span> <span class="type">error</span> &#123;</span><br><span class="line">  ctx := context.Background()</span><br><span class="line">  client, err := video.NewClient(ctx)</span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> err</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  op, err := client.AnnotateVideo(ctx, &amp;videopb.AnnotateVideoRequest&#123;</span><br><span class="line">    Features: []videopb.Feature&#123;</span><br><span class="line">      videopb.Feature_SHOT_CHANGE_DETECTION,</span><br><span class="line">    &#125;,</span><br><span class="line">    InputUri: file,</span><br><span class="line">  &#125;)</span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> err</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  fmt.Fprintf(w, <span class="string">&quot;Running....&quot;</span>)</span><br><span class="line">  resp, err := op.Wait(ctx)</span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> err</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// A single video was processed. Get the first result.</span></span><br><span class="line">  result := resp.AnnotationResults[<span class="number">0</span>].ShotAnnotations</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> _, shot := <span class="keyword">range</span> result &#123;</span><br><span class="line">    start, _ := ptypes.Duration(shot.StartTimeOffset)</span><br><span class="line">    end, _ := ptypes.Duration(shot.EndTimeOffset)</span><br><span class="line"></span><br><span class="line">    fmt.Fprintf(w, <span class="string">&quot;Shot: %s to %s\n&quot;</span>, start, end)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>這邊的Feature使用了<code>Feature_SHOT_CHANGE_DETECTION</code>，影片乍看之下感覺是同一個場景，我來研究看看到底output會是怎樣的變化。</p>
<blockquote>
<p>記得要先下載喔: <code>gsutil -m cp gs://cloud-samples-data/video/gbikes_dinosaur.mp4 .</code></p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Running....</span><br><span class="line">Shot: 0s to 5.166666s</span><br><span class="line">Shot: 5.233333s to 10.066666s</span><br><span class="line">Shot: 10.1s to 28.133333s</span><br><span class="line">Shot: 28.166666s to 42.766666s</span><br></pre></td></tr></table></figure>

<p>比對影片以後…<br><strong>Shot 0~5秒</strong>都是在拍腳踏車<br><strong>Shot 5~10秒</strong>在從腳踏車處移動到恐龍位置<br><strong>Shot 10~28秒</strong>在從恐龍左側拍恐龍<br><strong>Shot 28~42秒</strong>跑到了恐龍右側繼續拍恐龍</p>
<p>這些變化都能偵測出來，實在有趣。我們就趕快再來看下一個吧！</p>
<blockquote>
<p>想看Python詳細介紹，請看這裡：<a target="_blank" rel="noopener" href="https://cloud.google.com/video-intelligence/docs/shot_detection?authuser=1">https://cloud.google.com/video-intelligence/docs/shot_detection?authuser=1</a></p>
</blockquote>
<h3><span id="recognizing-text"></span><a href="#recognizing-text" class="header-anchor">#</a></h3><p>第二段來看看文字識別能力，據說可以偵測出影片裡的字，這又是能辨別到什麼程度呢？趕快把code複製下來看看。</p>
<figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TextDetectionGCS</span><span class="params">(w io.Writer, gcsURI <span class="type">string</span>)</span></span> <span class="type">error</span> &#123;</span><br><span class="line">  ctx := context.Background()</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Creates a client.</span></span><br><span class="line">  client, err := video.NewClient(ctx)</span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    log.Fatalf(<span class="string">&quot;Failed to create client: %v&quot;</span>, err)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  op, err := client.AnnotateVideo(ctx, &amp;videopb.AnnotateVideoRequest&#123;</span><br><span class="line">    InputUri: gcsURI,</span><br><span class="line">    Features: []videopb.Feature&#123;</span><br><span class="line">      videopb.Feature_TEXT_DETECTION,</span><br><span class="line">    &#125;,</span><br><span class="line">  &#125;)</span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    log.Fatalf(<span class="string">&quot;Failed to start annotation job: %v&quot;</span>, err)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  resp, err := op.Wait(ctx)</span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    log.Fatalf(<span class="string">&quot;Failed to annotate: %v&quot;</span>, err)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Only one video was processed, so get the first result.</span></span><br><span class="line">  result := resp.GetAnnotationResults()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> _, annotation := <span class="keyword">range</span> result.TextAnnotations &#123;</span><br><span class="line">    fmt.Fprintf(w, <span class="string">&quot;Text: %q\n&quot;</span>, annotation.GetText())</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Get the first text segment.</span></span><br><span class="line">    segment := annotation.GetSegments()[<span class="number">0</span>]</span><br><span class="line">    start, _ := ptypes.Duration(segment.GetSegment().GetStartTimeOffset())</span><br><span class="line">    end, _ := ptypes.Duration(segment.GetSegment().GetEndTimeOffset())</span><br><span class="line">    fmt.Fprintf(w, <span class="string">&quot;\tSegment: %v to %v\n&quot;</span>, start, end)</span><br><span class="line"></span><br><span class="line">    fmt.Fprintf(w, <span class="string">&quot;\tConfidence: %f\n&quot;</span>, segment.GetConfidence())</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Show the result for the first frame in this segment.</span></span><br><span class="line">    frame := segment.GetFrames()[<span class="number">0</span>]</span><br><span class="line">    seconds := <span class="type">float32</span>(frame.GetTimeOffset().GetSeconds())</span><br><span class="line">    nanos := <span class="type">float32</span>(frame.GetTimeOffset().GetNanos())</span><br><span class="line">    fmt.Fprintf(w, <span class="string">&quot;\tTime offset of the first frame: %fs\n&quot;</span>, seconds+nanos/<span class="number">1e9</span>)</span><br><span class="line"></span><br><span class="line">    fmt.Fprintf(w, <span class="string">&quot;\tRotated bounding box vertices:\n&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> _, vertex := <span class="keyword">range</span> frame.GetRotatedBoundingBox().GetVertices() &#123;</span><br><span class="line">      fmt.Fprintf(w, <span class="string">&quot;\t\tVertex x=%f, y=%f\n&quot;</span>, vertex.GetX(), vertex.GetY())</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>這次用的影片是googlework_short.mp4，前面大概有7秒的照片撥放，然後一直到20秒才有說13秒的話，影片總長度35秒，重點是<strong>非常模糊</strong>。</p>
<blockquote>
<p>不信？載下來看看<code>gsutil -m cp gs://python-docs-samples-tests/video/googlework_short.mp4 .</code></p>
</blockquote>
<p>好我們來看看output。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Text: &quot;(PLACE) SUR IN FOINT&quot;</span><br><span class="line">        Segment: 13.246566s to 13.246566s</span><br><span class="line">        Confidence: 0.804059</span><br><span class="line">        Time offset of the first frame: 13.246566s</span><br><span class="line">        Rotated bounding box vertices:</span><br><span class="line">                Vertex x=0.168750, y=0.650000</span><br><span class="line">                Vertex x=0.965625, y=0.650000</span><br><span class="line">                Vertex x=0.965625, y=0.861111</span><br><span class="line">                Vertex x=0.168750, y=0.861111</span><br><span class="line">Text: &quot;(PLACE) SUR IN FOINTF&quot;</span><br><span class="line">        Segment: 12.946266s to 12.946266s</span><br><span class="line">        Confidence: 0.846547</span><br><span class="line">        Time offset of the first frame: 12.946266s</span><br><span class="line">        Rotated bounding box vertices:</span><br><span class="line">                Vertex x=0.175000, y=0.205556</span><br><span class="line">                Vertex x=0.999993, y=0.211786</span><br><span class="line">                Vertex x=0.999528, y=0.406229</span><br><span class="line">                Vertex x=0.174535, y=0.399998</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">... 還有很多很多</span><br></pre></td></tr></table></figure>
<p>分析出了文字、時間、還有文字出現在哪裡。為什麼我特別節錄這段？因為她出現時間非常….短，大概不到一秒的這張圖：<br><img src="/blog/2019/09/16/ithelp-2019-day8/shot-text.jpg" alt="shot-text"><br>連這瞬間都不會放過，真的很強大。</p>
<p>今天玩的兩個服務都是以前要花很久時間才能做完的(frame by frame…)，現在丟進去就可以算出來，真希望有案子可以好好來玩這個服務。<br>好囉，如果你們要看更詳細的example，雖然沒有golang版本，但這邊有python版: <a target="_blank" rel="noopener" href="https://github.com/GoogleCloudPlatform/python-docs-samples/tree/master/video/cloud-client/analyze">https://github.com/GoogleCloudPlatform/python-docs-samples/tree/master/video/cloud-client/analyze</a></p>
<blockquote>
<p>今天github: <a target="_blank" rel="noopener" href="https://github.com/josephMG/ithelp-2019/tree/Day-8">https://github.com/josephMG/ithelp-2019/tree/Day-8</a></p>
</blockquote>
<p>今天就到這邊啦！謝謝各位。</p>

            
          </div>

          

          <footer class="article-footer">
            <a data-url="https://josephmg.github.io/blog/2019/09/16/ithelp-2019-day8/" data-id="clr8lqkpi004klbpxaflid7sj" class="article-share-link">Share</a>
            
            
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Google-AI/" rel="tag">Google AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/Video-Intelligence-AI/" rel="tag">Video Intelligence AI</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/%E9%90%B5%E4%BA%BA%E8%B3%BD/" rel="tag">鐵人賽</a></li></ul>

          </footer>

        </div>

        
          
<nav id="article-nav" class="white">
  <div class="nav-wrapper">
    <ul>
    
      <li id="article-nav-newer-container">
        <a
          href="/blog/2019/09/17/ithelp-2019-day9/"
          id="article-nav-newer"
          class="article-nav-link-wrap grey-text text-darken-1"
          title="[Day 9] Google Video Intelligence AI - 子系列最終章"
        >
          <i class="fa fa-arrow-left"></i>
          <span class="article-nav-title truncate">[Day 9] Google Video Intelligence AI - 子系列最終章</span>
        </a>
      </li>
    

    
      <li id="article-nav-older-container">
        <a
          href="/blog/2019/09/15/ithelp-2019-day7/"
          id="article-nav-older"
          class="article-nav-link-wrap grey-text text-darken-1 right-align"
          title="[Day 7] Google Video Intelligence AI - 2"
        >
          <span class="article-nav-title truncate">[Day 7] Google Video Intelligence AI - 2</span>
          <i class="fa fa-arrow-right"></i>
        </a>
      </li>
    

    </ul>
  </div>
</nav>


        
      </article>


      



    </div>
  </div>
</div>


  




  </div>

  <footer class="page-footer grey darken-2">
    <div class="footer-copyright">
      <div class="container">
        &copy; 2024 Joseph Chou

        <div class="right">
          Powered by <a href="http://hexo.io/" rel="nofollow noopener" class="white-text" target="_blank">Hexo</a>
        </div>
      </div>
    </div>
  </footer>

  
<script src="/generated/193-48f9b14976b9a526708f.js"></script>

<script src="/generated/668-d2e471b8dcd3790fc287.js"></script>

<script src="/generated/app-9afd2664faae5848b457.js"></script>

<script src="/generated/blog-ded2f363deb425b73a50.js"></script>


</body>
</html>
